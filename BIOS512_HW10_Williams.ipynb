{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d684172-4b94-42cf-bda2-e11952420d86",
   "metadata": {},
   "source": [
    "# Homework 10\n",
    "#### Course Notes\n",
    "**Language Models:** https://github.com/rjenki/BIOS512/tree/main/lecture17  \n",
    "**Unix:** https://github.com/rjenki/BIOS512/tree/main/lecture18  \n",
    "**Docker:** https://github.com/rjenki/BIOS512/tree/main/lecture19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d839a5ba-62f4-4699-baea-018afda70786",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "#### Make a language model that uses ngrams and allows the user to specify start words, but uses a random start if one is not specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c723909a-11e2-46e1-89a1-aec5ebf96986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/srv/rlibs’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "Installing package into ‘/srv/rlibs’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "Installing package into ‘/srv/rlibs’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "Installing package into ‘/srv/rlibs’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "Installing package into ‘/srv/rlibs’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "Installing package into ‘/srv/rlibs’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"tokenizers\")\n",
    "install.packages(\"stringr\")\n",
    "install.packages(\"httr\")\n",
    "install.packages(\"jsonlite\")\n",
    "install.packages(\"digest\")\n",
    "install.packages(\"viridis\")\n",
    "\n",
    "library(tokenizers)\n",
    "library(stringr)\n",
    "library(httr)\n",
    "library(jsonlite)\n",
    "library(digest)\n",
    "library(viridis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49",
   "metadata": {},
   "source": [
    "#### a) Make a function to tokenize the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "329399a2-825d-4932-b369-8426374ab2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_text <- function(text) {\n",
    "  tokenizers::tokenize_words(text, lowercase = TRUE, strip_punct = TRUE)[[1]]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86145513-294b-4894-a02c-8ae60e2c616e",
   "metadata": {},
   "source": [
    "#### b) Make a function generate keys for ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47122e2a-f63a-445c-8ec8-c3f67713711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_from <- function(ngram, sep = \"\\x1f\") {\n",
    "  paste(ngram, collapse = sep)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52988c2c-b230-467f-b519-72bc85b93b43",
   "metadata": {},
   "source": [
    "#### c) Make a function to build an ngram table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1612415-1fcd-4510-85c0-cf3d7f4c4c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_ngram_table <- function(tokens, n, sep = \"\\x1f\") {\n",
    "  if (length(tokens) < n) return(new.env(parent = emptyenv()))\n",
    "  tbl <- new.env(parent = emptyenv())\n",
    "  \n",
    "  for (i in seq_len(length(tokens) - n + 1L)) {\n",
    "    ngram <- tokens[i:(i + n - 2L)]\n",
    "    next_word <- tokens[i + n - 1L]\n",
    "    key <- paste(ngram, collapse = sep)\n",
    "    counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
    "    if (next_word %in% names(counts)) {\n",
    "      counts[[next_word]] <- counts[[next_word]] + 1L\n",
    "    } else {\n",
    "      counts[[next_word]] <- 1L\n",
    "    }\n",
    "    tbl[[key]] <- counts\n",
    "  }\n",
    "  tbl\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca6db37-abce-4705-9784-e1b898174f00",
   "metadata": {},
   "source": [
    "#### d) Function to digest the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "489378ac-74b6-48f1-9a20-af5562c3c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "digest_text <- function(text, n) {\n",
    "  tokens <- tokenize_text(text)\n",
    "  build_ngram_table(tokens, n)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fff313-0f13-479b-94df-7588c19fdd3d",
   "metadata": {},
   "source": [
    "#### e) Function to digest the url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94eb126b-e375-429a-8668-04a0f09f8b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "digest_url <- function(url, n) {\n",
    "  res <- httr::GET(url)\n",
    "  txt <- httr::content(res, as = \"text\", encoding = \"UTF-8\")\n",
    "  digest_text(txt, n)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a",
   "metadata": {},
   "source": [
    "#### f) Function that gives random start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20b50ae0-c26b-4ee1-9020-1e82c2af28af",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_start <- function(tbl, sep = \"\\x1f\") {\n",
    "  keys <- ls(envir = tbl, all.names = TRUE)\n",
    "  if (length(keys) == 0) stop(\"No n-grams available. Digest text first.\")\n",
    "  picked <- sample(keys, 1)\n",
    "  strsplit(picked, sep, fixed = TRUE)[[1]]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e998fb24-f2d6-41bc-a751-1f6accd3411f",
   "metadata": {},
   "source": [
    "#### g) Function to predict the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1fad83a-9049-4fe6-b097-4f65a5004198",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_next_word <- function(tbl, ngram, sep = \"\\x1f\") {\n",
    "  key <- paste(ngram, collapse = sep)\n",
    "  counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
    "  if (length(counts) == 0) return(NA_character_)\n",
    "  sample(names(counts), size = 1, prob = as.numeric(counts))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347f4002-4932-42c4-a4af-8689293a5857",
   "metadata": {},
   "source": [
    "#### h) Function that puts everything together. Specify that if the user does not give a start word, then the random start will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a7eb4fa-a901-466c-b819-9daa503d8039",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_ngram_generator <- function(tbl, n, sep = \"\\x1f\") {\n",
    "  force(tbl); n <- as.integer(n); force(sep)\n",
    "  function(start_words = NULL, length = 10L) {\n",
    "    # if user does not give a start word, use random start\n",
    "    if (is.null(start_words) || length(start_words) != n - 1L) {\n",
    "      start_words <- random_start(tbl, sep = sep)\n",
    "    }\n",
    "    word_sequence <- start_words\n",
    "    for (i in seq_len(max(0L, length - length(start_words)))) {\n",
    "      ngram <- tail(word_sequence, n - 1L)\n",
    "      next_word <- predict_next_word(tbl, ngram, sep = sep)\n",
    "      if (is.na(next_word)) break\n",
    "      word_sequence <- c(word_sequence, next_word)\n",
    "    }\n",
    "    paste(word_sequence, collapse = \" \")\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b742c67-907c-4bc7-8df1-c84fa65a7554",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "#### For this question, set `seed=2025`.\n",
    "#### a) Test your model using a text file of [Grimm's Fairy Tails](https://www.gutenberg.org/cache/epub/2591/pg2591.txt)\n",
    "#### i) Using n=3, with the start word(s) \"the king\", with length=15. \n",
    "#### ii) Using n=3, with no start word, with length=15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c4eb0b7-88f5-4ae6-b30c-429b46bb81bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2025)\n",
    "url_grimm <- \"https://www.gutenberg.org/cache/epub/2591/pg2591.txt\"  # Grimm’s Fairy Tales\n",
    "tbl_grimm <- digest_url(url_grimm, n = 3)\n",
    "gen_grimm <- make_ngram_generator(tbl_grimm, n = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f826fe25-5ae5-40cf-8cf9-38c323503031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grimm's Fairy Tales — Start words 'the king':\n",
      "[1] \"the king has forbidden me to marry another husband am not i shall ride upon\"\n"
     ]
    }
   ],
   "source": [
    "cat(\"Grimm's Fairy Tales — Start words 'the king':\\n\")\n",
    "output_grimm_king <- gen_grimm(start_words = c(\"the\", \"king\"), length = 15)\n",
    "print(output_grimm_king)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6e445d2-2c50-4310-a173-079b482cdb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grimm's Fairy Tales — Random start:\n",
      "[1] \"song was over the lake and herself into her little daughter’s hand and was about\"\n"
     ]
    }
   ],
   "source": [
    "cat(\"\\nGrimm's Fairy Tales — Random start:\\n\")\n",
    "output_grimm_random <- gen_grimm(length = 15)\n",
    "print(output_grimm_random)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e04b167-7f2c-4e0f-88e7-86ba5e8d74cc",
   "metadata": {},
   "source": [
    "#### b) Test your model using a text file of [Ancient Armour and Weapons in Europe](https://www.gutenberg.org/cache/epub/46342/pg46342.txt)\n",
    "#### i) Using n=3, with the start word(s) \"the king\", with length=15. \n",
    "#### ii) Using n=3, with no start word, with length=15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92389813-d7cc-4518-b1a3-23fb7a9af190",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_armour <- \"https://www.gutenberg.org/cache/epub/42322/pg42322.txt\"  # Ancient Armour and Weapons in Europe\n",
    "tbl_armour <- digest_url(url_armour, n = 3)\n",
    "gen_armour <- make_ngram_generator(tbl_armour, n = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "865e8a89-1f83-45cb-aa53-03e36d64bff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ancient Armour — Start words 'the king':\n",
      "[1] \"the king of vagabonds the mighty nimrod of sacred story and for moving with facility\"\n"
     ]
    }
   ],
   "source": [
    "cat(\"\\nAncient Armour — Start words 'the king':\\n\")\n",
    "output_armour_king <- gen_armour(start_words = c(\"the\", \"king\"), length = 15)\n",
    "print(output_armour_king)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fd56bc0-26d2-42bf-943c-0ccb4cf3cc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ancient Armour — Random start:\n",
      "[1] \"request was made by congress for his edification the surrounding plain i learned upon inquiry\"\n"
     ]
    }
   ],
   "source": [
    "cat(\"\\nAncient Armour — Random start:\\n\")\n",
    "output_armour_random <- gen_armour(length = 15)\n",
    "print(output_armour_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fb37ad-8e7c-4e62-afc0-ba46d46401fc",
   "metadata": {},
   "source": [
    "#### c) Explain in 1-2 sentences the difference in content generated from each source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c917b06-5039-40ba-b185-c8b1e12a5a22",
   "metadata": {},
   "source": [
    "The Grimm’s Fairy Tales model generated short, narrative phrases such as “the king has forbidden me to marry another husband…” and “song was over the lake…”, which reflect story-like and character-driven language typical of fairy tales. In contrast, the Ancient Armour model produced phrases like “the king of France it is…” and “regular gradations the first time amid the untrod wastes of humanity…”, which sound more historical, descriptive, and formal. This difference shows how the model captures the distinct vocabulary and tone of each text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e45972-f441-4d07-9073-fcddd6146cbd",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "#### a) What is a language learning model? \n",
    "#### b) Imagine the internet goes down and you can't run to your favorite language model for help. How do you run one locally?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a002b799-8f71-4704-908d-ed471c6b27a5",
   "metadata": {},
   "source": [
    "A) A language learning model is a type of machine learning model that predicts the probability of a sequence of words to understand and generate human language. It learns patterns from large amounts of text data and can then generate, summarize, or respond to text input by predicting the next most likely word/token. Examples include models like ChatGPT or Gemma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37e17c8-1e3c-46a8-9023-ec4f25205115",
   "metadata": {},
   "source": [
    "B) If the internet goes down, you can run a language model locally using OLLAMA, a tool that lets you download and run models directly on your computer's terminal. You would use the following commands to install and run the model: brew install ollama, ollama -v, ollama pull gemma3:1b, ollama serve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85a743b-f814-4a53-96e6-8bccb3d34ab8",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "#### Explain what the following vocab words mean in the context of typing `mkdir project` into the command line. If the term doesn't apply to this command, give the definition and/or an example.\n",
    "| Term | Meaning |  \n",
    "|------|---------|\n",
    "| **Shell** | A system that uses the environment to parse command line arguments (command mkdir), handle signals, read from standard input, and write to standard output. |\n",
    "| **Terminal emulator** | The application you're typing in that hosts the shell and provides the interface (ie: the terminal on a Mac) |\n",
    "| **Process** | An environment that communicates using standard input/output |\n",
    "| **Signal** |  A message sent to a process to control it  |\n",
    "| **Standard input** | The default way a process receives data (read characters from the input) |\n",
    "| **Standard output** | Normal output from a process (write characters to the output) |\n",
    "| **Command line argument** |  The information we pass to a process when we start it (ie. Project) |\n",
    "| **The environment** | All the stuff a process can see when it is running |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1332ff27-ca3f-4f7e-b4b9-07ead0358dd2",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "#### Consider the following command `find . -iname \"*.R\" | xargs grep read_csv`.\n",
    "#### a) What are the programs?\n",
    "#### b) Explain what this command is doing, part by part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84af44c3-c396-4b49-90ef-a3d9357ac1d0",
   "metadata": {},
   "source": [
    "A) The programs used in this command are: find, xargs, grep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e50a94f-3164-4d25-8358-8819cdc44a06",
   "metadata": {},
   "source": [
    "B) find . -iname \"*.R\" | xargs grep read_csv: in this statement \"find\" searches for files in a specified location. \".\" refers to the current working directory where the search will occur. \"-iname\" tells the search to look for files that match the \"*.R\" pattern. \"xargs\" takes the list of files produced by the \"find\" command and passes them as arguments to \"grep\", a patten matching program, which searches through text for the \"read_csv\" expression/string. Together, this command allows us to search each file with grep by using zargs to first find a set of files and then search for them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69771ac7-865e-4d82-aa25-a39e7c1ab095",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "#### Install Docker on your machine. See [here](https://github.com/rjenki/BIOS512/blob/main/lecture18/docker_install.md) for instructions. \n",
    "#### a) Show the response when you run `docker run hello-world`.\n",
    "#### b) Access Rstudio through a Docker container. Set your password and make sure your files show up on the Rstudio server. Type the command and the output you get below.\n",
    "#### c) How do you log in to the RStudio server?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb4855d-8b6d-4887-8b8a-11ff6b6a8533",
   "metadata": {},
   "source": [
    "A)\n",
    "Hello from Docker!\n",
    "This message shows that your installation appears to be working correctly.\n",
    " To generate this message, Docker took the following steps:\n",
    " 1. The Docker client contacted the Docker daemon.\n",
    " 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
    "    (arm64v8)\n",
    " 3. The Docker daemon created a new container from that image which runs the\n",
    "    executable that produces the output you are currently reading.\n",
    " 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
    "    to your terminal.\n",
    "\n",
    "To try something more ambitious, you can run an Ubuntu container with:\n",
    " $ docker run -it ubuntu bash\n",
    "\n",
    "Share images, automate workflows, and more with a free Docker ID:\n",
    " https://hub.docker.com/\n",
    "\n",
    " For more examples and ideas, visit:\n",
    " https://docs.docker.com/get-started/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e85ec96-a78d-43d4-90f3-e1298f43981e",
   "metadata": {},
   "source": [
    "B)\n",
    "command: docker run -d -p 8787:8787 -e PASSWORD=yourpassword rocker/rstudio\n",
    "output: \n",
    "bellawilliams@Bellas-MacBook-Air-6 ~ % docker run -d -p 8787:8787 -e PASSWORD=yourpassword rocker/rstudio\n",
    "Unable to find image 'rocker/rstudio:latest' locally\n",
    "latest: Pulling from rocker/rstudio\n",
    "3665120d345d: Pulling fs layer \n",
    "b8a35db46e38: Pulling fs layer \n",
    "2c9ba66d5dbe: Pulling fs layer \n",
    "2034506aa72f: Pulling fs layer \n",
    "bcce866b1806: Pulling fs layer \n",
    "91ed5b86de88: Pulling fs layer \n",
    "9c1a4a0706b7: Pulling fs layer \n",
    "e2804bef35e8: Pulling fs layer \n",
    "a730ff463d58: Pull complete \n",
    "cc9c938c1f51: Pull complete \n",
    "bc9245ceaac5: Pull complete \n",
    "39038e16d1ba: Pull complete \n",
    "191985778909: Pull complete \n",
    "5b219f62ce36: Pull complete \n",
    "abd0190d83fb: Pull complete \n",
    "08e74fd5985d: Pull complete \n",
    "664fb1818bbb: Pull complete \n",
    "5d246ec925db: Pull complete \n",
    "Digest: sha256:9f85211a666fb426081a6f5a01f9f9f51655262258419fa21e0ce38a5afc78d8\n",
    "Status: Downloaded newer image for rocker/rstudio:latest\n",
    "639938fde6824ba384d2a311b8e2a7e5c33d04afbeb6c34972864d23e059e94f\n",
    "bellawilliams@Bellas-MacBook-Air-6 ~ %\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273b84a5-3752-4486-aec0-14887960c184",
   "metadata": {},
   "source": [
    "C) go to http://localhost:8787 in browser\n",
    "login using username: rstudio password: yourpassword"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
