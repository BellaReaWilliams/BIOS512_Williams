{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19bce45a-918d-469e-89c8-d948c5f4b878",
   "metadata": {},
   "source": [
    "BIOS 512\n",
    "HOMEWORK 8\n",
    "BELLA WILLIAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbdef86-462f-44a1-9781-cfe2f328a747",
   "metadata": {},
   "source": [
    "QUESTION 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6492b3-db1c-40d0-afd6-80bccd8eb313",
   "metadata": {},
   "source": [
    "A) Given a number of clusters to search for N:\n",
    "\n",
    "1. Assign each point to a cluster N at random.\n",
    "2. Calculate the mean position of each cluster using the previous assignments.\n",
    "3. Loop through the points - assign each point to the cluster to whose center it is closest.\n",
    "4. Repeat this process until the centers stop moving around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e49ef634-74bf-4308-b3f4-2a99b0fc4f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.2     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2  \u001b[39m 3.4.2     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.2     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.1     \n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0ecc64-187a-4b7d-aace-8b5802a2282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd060b92-d78b-480f-abdd-1b3d07c9738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ee29f-85a3-44ce-b6b2-7269acf792f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(readr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d8dfbf-c755-4e84-8dc2-5b4a86baa9d6",
   "metadata": {},
   "source": [
    "B) Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1f63a5-f57f-4604-b7dd-751326c93c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_randomly <- function(n_points, n_clusters){\n",
    "sample(1:n_clusters, size = n_points, replace = TRUE)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c63d108-1208-4546-963a-f6a7a7e8ab91",
   "metadata": {},
   "source": [
    "C) Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb51f5d6-f3e6-4bb3-9c0a-8f6bf62224e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cluster_means <- function(data, labels){\n",
    "  library(dplyr)\n",
    "  \n",
    "  data %>%\n",
    "    mutate(label__ = labels) %>%\n",
    "    group_by(label__) %>%       \n",
    "\n",
    "    summarize(across(\n",
    "      .cols = where(is.numeric), \n",
    "      .fns = mean, \n",
    "      .names = \"{.col}\"\n",
    "    )) %>%\n",
    "    \n",
    "    rename(label = label__) %>%\n",
    "    ungroup() %>%\n",
    "    arrange(label)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025e558c-d2a3-477a-9b25-a074055d5a58",
   "metadata": {},
   "source": [
    "D) Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66236b41-706b-4eb1-8f60-c5b4e641d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_cluster <- function(data, means){\n",
    "\n",
    "  X <- as.matrix(data) \n",
    "  C <- as.matrix(means %>% select(-label)) \n",
    "  \n",
    "  X_sq <- rowSums(X * X)\n",
    "  C_sq <- rowSums(C * C)\n",
    "  \n",
    "\n",
    "  dist_sq_matrix <- outer(X_sq, C_sq, FUN = \"+\") - 2 * (X %*% t(C))\n",
    "  \n",
    "\n",
    "  new_labels <- max.col(-dist_sq_matrix)\n",
    "  \n",
    "  return(new_labels)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922232e2-a9f3-479c-9705-20dd1145cb17",
   "metadata": {},
   "source": [
    "E) Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45a7b2cf-fe4c-4849-88c7-7cce2622ed43",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_done <- function(old_means, new_means, eps = 1e-6){\n",
    "\n",
    "  om <- old_means %>% select(-label) %>% as.matrix()\n",
    "  nm <- new_means %>% select(-label) %>% as.matrix()\n",
    "  \n",
    "  distances <- sqrt(rowSums((om - nm)^2))\n",
    "  \n",
    "  if (mean(distances) < eps) TRUE else FALSE\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c4238f-e55f-4644-a6ce-bae6b9a232a8",
   "metadata": {},
   "source": [
    "F) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b350ec69-51ef-42e9-a8f7-e8f86535810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mykmeans <- function(data, n_clusters, eps = 1e-6, max_iter = 100){\n",
    "  \n",
    "  labels <- label_randomly(nrow(data), n_clusters)\n",
    "  \n",
    "  old_means <- get_cluster_means(data, labels)\n",
    "  \n",
    "  done <- FALSE\n",
    "  iter <- 0\n",
    "\n",
    "  while (!done && iter < max_iter){\n",
    "\n",
    "    labels <- assign_cluster(data, old_means)\n",
    "\n",
    "    new_means <- get_cluster_means(data, labels)\n",
    "    \n",
    "    if (kmeans_done(old_means, new_means, eps)){\n",
    "      done <- TRUE\n",
    "    }\n",
    "    \n",
    "    old_means <- new_means\n",
    "    iter <- iter + 1\n",
    "  }\n",
    "  \n",
    "  if (iter == max_iter && !done) {\n",
    "    warning(\"K-Means did not converge within the maximum number of iterations.\")\n",
    "  }\n",
    "  \n",
    "  cat(paste(\"K-Means converged after\", iter, \"iterations.\\n\"))\n",
    "\n",
    "  return(list(labels = labels, means = new_means))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec69734-a0c3-40a6-8aa7-1200203f2992",
   "metadata": {},
   "source": [
    "QUESTION 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fce18ba-e17c-42ec-98b9-45503e42354e",
   "metadata": {},
   "source": [
    "A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6a416ac-3721-435a-9aa4-b90f5dee5502",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m900\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m250\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[32mdbl\u001b[39m (250): 0, 1.00401606425703, 2.00803212851406, 3.01204819277108, 4.016064...\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    }
   ],
   "source": [
    "voltages_df <- read_csv(\"voltages_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8158052-b489-4077-a233-e7d03d5058b1",
   "metadata": {},
   "source": [
    "B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f00f344-1d69-4123-84f3-ae493ebb580f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Running custom mykmeans with k = 3\"\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in label_randomly(nrow(data), n_clusters): could not find function \"label_randomly\"\n",
     "output_type": "error",
     "traceback": [
      "Error in label_randomly(nrow(data), n_clusters): could not find function \"label_randomly\"\nTraceback:\n",
      "1. mykmeans(voltages_df, n_clusters)"
     ]
    }
   ],
   "source": [
    "n_clusters <- 3\n",
    "\n",
    "print(paste(\"Running custom mykmeans with k =\", n_clusters))\n",
    "my_results <- mykmeans(voltages_df, n_clusters)\n",
    "\n",
    "print(\"--- Custom mykmeans Results (Cluster Labels) ---\")\n",
    "print(my_results$labels)\n",
    "\n",
    "print(\"--- Custom mykmeans Results (Cluster Means/Centroids) ---\")\n",
    "print(my_results$means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81295dcc-f7b7-416f-8658-e663c11015dc",
   "metadata": {},
   "source": [
    "C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b31f0-3f87-4d02-a634-dff5f15644ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters <- 3 \n",
    "\n",
    "print(\"\\n--- RESULTS FROM CUSTOM mykmeans (Part b) ---\")\n",
    "my_results <- mykmeans(voltages_df, n_clusters)\n",
    "\n",
    "\n",
    "print(\"Cluster Labels (mykmeans, in $labels):\")\n",
    "print(my_results$labels)\n",
    "\n",
    "print(\"Cluster Means (mykmeans, in $means):\")\n",
    "print(my_results$means)\n",
    "\n",
    "voltages_matrix <- as.matrix(voltages_df)\n",
    "\n",
    "print(\"\\n--- RESULTS FROM R's BUILT-IN kmeans (Part c) ---\")\n",
    "\n",
    "r_results <- stats::kmeans(voltages_matrix, centers = n_clusters, nstart = 25) \n",
    "\n",
    "print(\"Cluster Labels (R's kmeans, in $cluster):\")\n",
    "print(r_results$cluster) \n",
    "\n",
    "print(\"Cluster Means (R's kmeans, in $centers):\")\n",
    "print(r_results$centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261f1832-1442-4567-be76-46965b0efd21",
   "metadata": {},
   "source": [
    "D) The raw lists of cluster labels are not identical because the label numbers (1, 2, 3) are arbitrary identifiers, meaning that a point labeled '1' in my function might be labeled '2' in R's function. However, when comparing the final cluster means, the centroids are effectively the same across both functions, indicating both algorithms converged to the same three physical locations in the data space. For instance, my custom kmeans cluster 1 values (-1.03,0.938) correspond with R's cluster 2 values (-1.031463,0.9381238). This result confirms that my custom implementation of the K-Means algorithm successfully mirrored the outcome of R's built-in function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b52af2c-f886-49e8-8abc-46ae301bcc44",
   "metadata": {},
   "source": [
    "QUESTION 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbb8668-966e-4dd7-881f-489f6cd2ac55",
   "metadata": {},
   "source": [
    "A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ffa28e-91a0-47ca-98ce-d1be4722268c",
   "metadata": {},
   "source": [
    "When using a for loop, cluster assignment is done iteratively:\n",
    "1. Loop through each data point one by one.\n",
    "2. For each point, loop through all cluster centroids.\n",
    "3. Compute the distance from the point to each centroid (usually squared Euclidean distance).\n",
    "4. Determine which centroid is closest to the point.\n",
    "5. Assign the point to that cluster.\n",
    "6. Repeat for all points to complete one iteration of cluster reassignment.\n",
    "\n",
    "This method is straightforward and mirrors the algorithm description directly, but it can be slow for large datasets, since it explicitly computes distances one point at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0da65ec-7fee-47f7-8372-ad100799655b",
   "metadata": {},
   "source": [
    "B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78634502-4974-48a2-a4c8-9c678b972320",
   "metadata": {},
   "source": [
    "When using vectorization, explicit loops are eliminated by performing operations on entire arrays or matrices at once:\n",
    "\n",
    "1. Represent the data as a matrix and the centroids as another matrix.\n",
    "2. Compute the distances from all points to all centroids in one matrix operation, e.g., using matrix subtraction and row-wise sums.\n",
    "3. For each point, find the index of the minimum distance across centroids.\n",
    "4. Assign clusters based on these indices.\n",
    "\n",
    "Vectorization leverages optimized internal code and avoids the overhead of repeated loops."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d28d29e-929d-4d2f-b4af-8d64969e6dcf",
   "metadata": {},
   "source": [
    "C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53f4d3c-9953-4c2f-8833-fad04e7eae9c",
   "metadata": {},
   "source": [
    "Vectorized code is more efficient than using for loops because it performs operations on entire matrices at once, avoiding the overhead of repeatedly iterating through points. For loops are easier to read and understand but can become very slow for large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea720d6-abd8-442f-9b06-5bc5cd5be9da",
   "metadata": {},
   "source": [
    "QUESTION 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84990608-b150-42eb-8b51-d7d1dba2c7a5",
   "metadata": {},
   "source": [
    "K-means can fail when the clusters in the data are not roughly spherical, have very different sizes, or have overlapping or irregular shapes. This failure happens because K-means assumes that each cluster is defined solely by its centroid, and that points belong to the cluster whose center is closest. Since K-means has no way of accounting for variance, standard deviation, or multiple clusters sharing the same center, its simple algorithm can produce misleading results in these situations, despite being very efficient under ideal assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c45841-452b-48b3-b516-f8e44fd37128",
   "metadata": {},
   "source": [
    "QUESTION 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376632fc-3004-45aa-9de3-39603acee318",
   "metadata": {},
   "source": [
    "Gaussian Mixture Models assume that the data are drawn from multiple Gaussian distributions, each with its own mean and covariance. This allows clusters to have different sizes, shapes, and orientations, unlike K-means which assumes spherical, equally sized clusters. The parameters of each Gaussian are estimated from the data using expectation-maximization, iteratively refining cluster assignments to best fit the distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b292ca-00cf-4cea-95d9-62a485d919c5",
   "metadata": {},
   "source": [
    "QUESTION 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84632f13-405d-4ca8-9dbe-3e9ca9a9dddc",
   "metadata": {},
   "source": [
    "Spectral clustering assumes that points are more likely to belong to the same cluster if they are close or similar according to some metric. This minimal assumption allows it to work on data that do not reside in a vector space and even on purely relational data, such as graphs or adjacency matrices. By using the Graph Laplacian and its eigenvectors, spectral clustering creates a low-dimensional representation of the connectivity structure, which can then be clustered with standard methods like k-means, capturing complex cluster shapes that traditional methods might miss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321bb09c-38ff-41f0-9fae-8ab427ddbd4c",
   "metadata": {},
   "source": [
    "QUESTION 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653ac7d8-2331-4539-b254-a539d249c220",
   "metadata": {},
   "source": [
    "The gap statistic method is a standard approach for choosing the number of clusters in a dataset. It works by comparing the clustering results for each value of \n",
    "𝐾\n",
    "K to a reference dataset where the points are randomized within the same domain. By measuring the difference in dispersion between the real and randomized data, we identify the “knee” in the gap, which suggests the most appropriate number of clusters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
